{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APS360_Project_Group_11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a54de338ce7846a984c495bbbdccb69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_797da68db93542d0ba0348bb9ca8761d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54c80fcdc377426ab0e25b2578208ac4",
              "IPY_MODEL_7f94438b97a24625b4cee26b23f454f6"
            ]
          }
        },
        "797da68db93542d0ba0348bb9ca8761d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54c80fcdc377426ab0e25b2578208ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f59498010104ca8a10eb0c2466fa3aa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f960aced4e0f42baae608c8735cf7a33"
          }
        },
        "7f94438b97a24625b4cee26b23f454f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ade0b1354ac242378f15c7f79b6a3e4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [07:33&lt;00:00, 226kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_158513e40e2140a5a85abce9956bfa31"
          }
        },
        "1f59498010104ca8a10eb0c2466fa3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f960aced4e0f42baae608c8735cf7a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ade0b1354ac242378f15c7f79b6a3e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "158513e40e2140a5a85abce9956bfa31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidYichengWei/APS360-Project/blob/main/APS360_Project_Group_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoqW915USBuw"
      },
      "source": [
        "This is our APS360 Project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8v1ORw01KxH"
      },
      "source": [
        "Goals:\n",
        "1. Data processing: put images into two folders, one containing images with mask, the other containing images without mask. Only use faces that have pictures of masked face with a resolution of at least 100*100 pixels. Use resize to adjust to 224*224 pixels\n",
        "\n",
        "2. Primary model: PDSN model, using ResNet50 as pretrained model for the CNN part\n",
        "\n",
        "3. Baseline model: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwhCUV9n9Npd"
      },
      "source": [
        "Data Processing:\n",
        "\n",
        "1.   resize to 224x224\n",
        "2.   split into masked and no-mask folders\n",
        "3.   get mask and nomask loaders\n",
        "4. \n",
        "5.   \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVoZ-NqZB6Y4"
      },
      "source": [
        "Mar 25th meeting\n",
        "\n",
        "Justin: data processing, try mask generator, Mar 28th\n",
        "Yicheng, Bill: change model structures, Mar 2nd\n",
        "Helen: tune hyparameters, Mar 2nd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEL-uz_Kl0n_"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giGs7DjZl0KB"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2bo7XNXo24-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38499dbf-7a2b-4fed-976c-b7236cafa7d3"
      },
      "source": [
        "#setup Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miTF2iooUF-D"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwJZGXv1Q7z5"
      },
      "source": [
        "# The code was run on local computer\n",
        "# resize all the images to 224x224 format\n",
        "import os\n",
        "from PIL import Image\n",
        "import shutil\n",
        "desiredSize = (224, 224)\n",
        "\n",
        "nomaskDir = 'self-built-masked-face-recognition-dataset/AFDB_face_dataset'\n",
        "maskDir = 'self-built-masked-face-recognition-dataset/AFDB_masked_face_dataset'\n",
        "\n",
        "#'self-built-masked-face-recognition-dataset/AFDB_face_dataset/perspon\n",
        "nomaskPerson = os.listdir(nomaskDir)\n",
        "nomaskDirPerson = [os.path.join(nomaskDir, person) for person in nomaskPerson]\n",
        "maskPerson = os.listdir(maskDir)\n",
        "maskDirPerson = [os.path.join(maskDir, person) for person in maskPerson]\n",
        "\n",
        "# resize all pics to 224x224\n",
        "totalNum = 0\n",
        "for personFolder in nomaskDirPerson:\n",
        "    for image in os.listdir(personFolder):\n",
        "        imageFullPath = os.path.join(personFolder, image)\n",
        "        print(imageFullPath)\n",
        "        im = Image.open(imageFullPath)\n",
        "        resized_im = im.resize(desiredSize)\n",
        "        resized_im.save(imageFullPath)\n",
        "        totalNum+=1\n",
        "\n",
        "\n",
        "for personFolder in maskDirByPerson:\n",
        "    for image in os.listdir(personFolder):\n",
        "        imageFullPath = os.path.join(personFolder, image)\n",
        "        print(imageFullPath)\n",
        "        im = Image.open(imageFullPath)\n",
        "        resized_im = im.resize(desiredSize)\n",
        "        resized_im.save(imageFullPath)\n",
        "        \n",
        "        totalNum+=1\n",
        "print(totalNum)        \n",
        "## 92671\n",
        "\n",
        "\n",
        "# remove empty folders\n",
        "emptyPersonName = []\n",
        "for personFolder in nomaskDirPerson:\n",
        "    allImage = os.listdir(personFolder)\n",
        "    if len(allImage) == 0:\n",
        "        emptyPerson.append(personFolder)\n",
        "        totalEmpty += 1\n",
        "\n",
        "for personFolder in maskDirPerson:\n",
        "    allImage = os.listdir(personFolder)\n",
        "    if len(allImage) == 0:\n",
        "        emptyPerson.append(personFolder)\n",
        "        totalEmpty += 1\n",
        "\n",
        "personName = []\n",
        "for entry in emptyPerson:\n",
        "    parts = entry.split('/')\n",
        "    name = parts[len(parts)-1]\n",
        "    personName.append(name)\n",
        "\n",
        "for name in personName:\n",
        "    shutil.rmtree(os.path.join(maskDir, name))\n",
        "    shutil.rmtree(os.path.join(nomaskDir, name))\n",
        "\n",
        "# remove mismatched folders\n",
        "mismatch = []\n",
        "for name in nomaskDirPerson:\n",
        "    if name not in maskDirByPerson:\n",
        "        mismatch.append(name)\n",
        "\n",
        "for name in maskDirByPerson:\n",
        "    if name not in nomaskDirPerson:\n",
        "        mismatch.append(name)\n",
        "\n",
        "# remove repetitive entries\n",
        "mismatch = list(dict.fromkeys(mismatch))\n",
        "mismatchFullpath = []\n",
        "for mis in mismatch:\n",
        "    for dir in nomaskFullPathByPerson:\n",
        "        if mis in dir:\n",
        "            mismatchFullpath.append(dir)\n",
        "    \n",
        "    for dir in maskFullPathByPerson:\n",
        "        if mis in dir:\n",
        "            mismatchFullpath.append(dir)\n",
        "\n",
        "for entry in mismatchFullpath:\n",
        "    shutil.rmtree(entry)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itLkP0mw5_aj"
      },
      "source": [
        "# Get pair loader function that should be run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tjrnIajpEJ4"
      },
      "source": [
        "maskRootAddr = '/content/drive/My Drive/Colab Notebooks/pair-dataset/mask/'\n",
        "nomaskRootAddr = '/content/drive/My Drive/Colab Notebooks/pair-dataset/nomask/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHiw-7hKnjDC"
      },
      "source": [
        "# function to create data loader that gives a pair of image to train our FDM network\n",
        "\"\"\" note maskRootAddr and nomaskRootAddr must be the pair folders \"\"\"\n",
        "\"\"\" \n",
        "    when split is set to True, this functions returns trainLoader, valLoader, testLoader\n",
        "    else only a single loader is returned\n",
        "\"\"\"\n",
        "\"\"\" usage of this loader is:\n",
        "      loader = getPairLoder(blah blah blah)\n",
        "      for i, data in enumerate(loader):\n",
        "          # i is not used\n",
        "          # data[0][j] is [maskImage, nomaskImage], where j is 0~batchSize\n",
        "          # data[1] is 1d tensor of labels of size batchSize\n",
        "\"\"\"\n",
        "def getPairLoader(maskRootAddr, nomaskRootAddr, batchSize=32, split=True):\n",
        "    allmaskImages = datasets.ImageFolder(root=maskRootAddr, transform=transforms.ToTensor())\n",
        "    allnomaskImages = datasets.ImageFolder(root=nomaskRootAddr, transform=transforms.ToTensor())\n",
        "\n",
        "    maskClassStartInd = []\n",
        "    maskClassStartInd.append(0)\n",
        "    for i in range(len(allmaskImages)):\n",
        "        if i+1 == len(allmaskImages): break\n",
        "        if allmaskImages[i][1] != allmaskImages[i+1][1]:\n",
        "            maskClassStartInd.append(i+1)\n",
        "\n",
        "    nomaskClassStartInd = [] \n",
        "    nomaskClassStartInd.append(0)\n",
        "    for i in range(len(allnomaskImages)):\n",
        "        if i+1 == len(allnomaskImages): break\n",
        "        if allnomaskImages[i][1] != allnomaskImages[i+1][1]:\n",
        "            nomaskClassStartInd.append(i+1)\n",
        "\n",
        "    allPairs = []\n",
        "    nomaskInd = 0\n",
        "    for i in range(len(maskClassStartInd)):\n",
        "        maskInd = maskClassStartInd[i]\n",
        "        nomaskInd = nomaskClassStartInd[i]\n",
        "        for ind in range(5):\n",
        "            maskImage = allmaskImages[maskInd+ind][0]\n",
        "            nomaskImage = allnomaskImages[nomaskInd+ind][0]\n",
        "            pair = [maskImage, nomaskImage]\n",
        "            allPairs.append([pair, i])\n",
        "    totalPair = len(allPairs)\n",
        "    allIndices = list(range(totalPair))\n",
        "    np.random.shuffle(allIndices)\n",
        "    if split==True:\n",
        "        split1 = int(totalPair*0.6)\n",
        "        split2 = int(totalPair*0.8)\n",
        "        trainSampler = SubsetRandomSampler(allIndices[:split1])\n",
        "        valSampler = SubsetRandomSampler(allIndices[split1:split2])\n",
        "        testSampler = SubsetRandomSampler(allIndices[split2:])\n",
        "        trainLoader = torch.utils.data.DataLoader(allPairs, batch_size=batchSize, sampler=trainSampler)\n",
        "        valLoader = torch.utils.data.DataLoader(allPairs, batch_size=batchSize, sampler=valSampler)\n",
        "        testLoader = torch.utils.data.DataLoader(allPairs, batch_size=batchSize, sampler=testSampler)\n",
        "        return trainLoader, valLoader, testLoader\n",
        "    else:\n",
        "        sampler = SubsetRandomSampler(allIndices)\n",
        "        return torch.utils.data.DataLoader(allPairs, batch_size=batchSize, sampler=sampler)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUfZ1BKWpsZ1"
      },
      "source": [
        "train_pair_loader, valid_pair_loader, test_pair_loader = getPairLoader(maskRootAddr, nomaskRootAddr, 32, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fHnJDgCvAuQ"
      },
      "source": [
        "# Check size of inputs\n",
        "for i, data in enumerate(train_pair_loader):\n",
        "      # Get the inputs\n",
        "      inputs, labels = data\n",
        "      x = inputs[1] # 1 means no mask\n",
        "      print(x.shape)\n",
        "      # x = x.permute(1, 2, 0)      # move the channel dimension to the end to plot\n",
        "      # plt.imshow(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xCT9mnmRz1K"
      },
      "source": [
        "# get loaders\n",
        "def getLoader(rootAddr, batchSize=32):\n",
        "    allImages = datasets.ImageFolder(root=maskAddr, transform=transforms.ToTensor())\n",
        "    imgLen = len(allImages)\n",
        "    print(\"There are a total of {} images\".format(imgLen))\n",
        "    allIndices = list(range(imgLen))\n",
        "    np.random.shuffle(allIndices)\n",
        "    split1 = int(0.6*imgLen)\n",
        "    split2 = int(0.8*imgLen)\n",
        "    trainInd = allIndices[ : split1]\n",
        "    valInd = allIndices[split1:split2]\n",
        "    testInd = allIndices[split2: ]\n",
        "    trainSampler = SubsetRandomSampler(trainInd)\n",
        "    valSampler = SubsetRandomSampler(valInd)\n",
        "    testSampler = SubsetRandomSampler(testInd)\n",
        "\n",
        "    trainLoader = torch.utils.data.DataLoader(allImages, batch_size=batchSize, sampler=trainSampler)\n",
        "    valLoader = torch.utils.data.DataLoader(allImages, batch_size=batchSize, sampler=valSampler)\n",
        "    testLoader = torch.utils.data.DataLoader(allImages, batch_size=batchSize, sampler=testSampler)\n",
        "    \n",
        "    return trainLoader, valLoader, testLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgrBosOBvatE"
      },
      "source": [
        "## Loaders update March 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp2gNWS8vfX5"
      },
      "source": [
        "\"\"\"\n",
        "    inputs:\n",
        "        maskRootAddr & nomaskRootAddr & batchSize are as before and self-explanatory\n",
        "\n",
        "        numPeople is the number of people we will use in our dataset\n",
        "        \n",
        "        *Note pair loader uses the last numPeople classes, and ANN loader uses the first numPeople classes\n",
        "         So need to make sure they dont overlap when calling these 2 functions\n",
        "    outputs:\n",
        "        return training, validation, and test loaders if wantTest is set to True\n",
        "        return training and validation if wantTest is False\n",
        "\n",
        "\"\"\"\n",
        "\"\"\" \n",
        "    usage:\n",
        "    \n",
        "    for i, data in enumerate(trainLoader):\n",
        "        print(len(data[0]))\n",
        "        # 2\n",
        "        print(data[0][0].shape) # this is the no mask images\n",
        "        # torch.Size([32, 3, 224, 224])\n",
        "        print(data[0][1].shape) # this is the masked images\n",
        "        # torch.Size([32, 3, 224, 224])\n",
        "        print(data[1].shape)    # this is the labels\n",
        "        # torch.Size([32])\n",
        "        break\n",
        "\"\"\"\n",
        "def getNewPairLoader(maskRootAddr, nomaskRootAddr, batchSize=32, wantTest=False, numPeople=20):\n",
        "    # totalClassNum = len(os.listdir(maskRootAddr))\n",
        "    totalClassNum = 173\n",
        "    wantClass = totalClassNum-numPeople\n",
        "    \n",
        "    allmaskImages = datasets.ImageFolder(root=maskRootAddr, transform=transforms.ToTensor())\n",
        "    # get index of the first occurence of our desired class\n",
        "    wantmaskInd = wantnomaskInd = 0\n",
        "    for i in range(len(allmaskImages)):\n",
        "        if allmaskImages[1] == wantClass:\n",
        "            wantmaskInd = i\n",
        "            break\n",
        "    #allmaskImages = allmaskImages[wantmaskInd:]\n",
        "    \n",
        "    allnomaskImages = datasets.ImageFolder(root=nomaskRootAddr, transform=transforms.ToTensor())\n",
        "    for i in range(len(allnomaskImages)):\n",
        "        if allmaskImages[1] == wantClass:\n",
        "            wantnomaskInd = i\n",
        "            break\n",
        "    #allnomaskImages = allnomaskImages[wantnomaskInd:]\n",
        "\n",
        "\n",
        "    allClasses = range(wantClass, totalClassNum)\n",
        "    # we want only training and validation set\n",
        "    if wantTest == False:\n",
        "        train_pair_list, val_pair_list = [], []\n",
        "        for clas in range(numPeople):\n",
        "            maskEndInd = nomaskEndInd = 0\n",
        "            for i in range(wantmaskInd, len(allmaskImages)):\n",
        "                if i+1 != len(allmaskImages):\n",
        "                    if allmaskImages[i][1]!=allmaskImages[i+1][1]:\n",
        "                        maskEndInd = i+1\n",
        "                        break\n",
        "                else:\n",
        "                    maskEndInd = -1\n",
        "                    break\n",
        "            classmaskImages = []        \n",
        "            for i in range(wantmaskInd, maskEndInd if maskEndInd!=-1 else len(allmaskImages)):\n",
        "                classmaskImages.append(allmaskImages[i])\n",
        "            wantmaskInd = maskEndInd\n",
        "            \n",
        "            \n",
        "            for i in range(wantnomaskInd, len(allnomaskImages)):\n",
        "                if i+1 != len(allnomaskImages):                \n",
        "                    if allnomaskImages[i][1]!=allnomaskImages[i+1][1]:\n",
        "                        nomaskEndInd = i+1\n",
        "                        break\n",
        "                else:\n",
        "                    nomaskEndInd = -1\n",
        "                    break\n",
        "            classnomaskImages = []\n",
        "            for i in range(wantnomaskInd, nomaskEndInd if nomaskEndInd!=-1 else len(allnomaskImages)):\n",
        "                classnomaskImages.append(allnomaskImages[i])\n",
        "            wantnomaskInd = nomaskEndInd\n",
        "\n",
        "            # next, pair up \n",
        "            mask_train = classmaskImages[:int(len(classmaskImages)*0.7)]\n",
        "            mask_val = classmaskImages[int(len(classmaskImages)*0.7):]\n",
        "            \n",
        "            for i in range(200):\n",
        "                int1 = np.random.randint(0, len(classnomaskImages)-1)\n",
        "                int2 = np.random.randint(0, len(mask_train)-1)\n",
        "                train_pair_list.append(([classnomaskImages[int1][0], mask_train[int2][0]], mask_train[int2][1]))\n",
        "\n",
        "            for i in range(80):\n",
        "                int1 = np.random.randint(0, len(classnomaskImages)-1)\n",
        "                int2 = np.random.randint(0, len(mask_val)-1)\n",
        "                val_pair_list.append(([classnomaskImages[int1][0], mask_val[int2][0]], mask_val[int2][1]))\n",
        "        \n",
        "        trainInd = range(len(train_pair_list))\n",
        "        valInd = range(len(val_pair_list))\n",
        "\n",
        "        trainSampler = SubsetRandomSampler(trainInd)\n",
        "        valSampler = SubsetRandomSampler(valInd)\n",
        "        trainLoader = torch.utils.data.DataLoader(train_pair_list, batch_size=batchSize, sampler=trainSampler)\n",
        "        valLoader = torch.utils.data.DataLoader(val_pair_list, batch_size=batchSize, sampler=valSampler)\n",
        "        return trainLoader, valLoader\n",
        "\n",
        "    # we want training validation and test set\n",
        "    else:\n",
        "        train_pair_list, val_pair_list, test_pair_list = [], [], []\n",
        "        \n",
        "        for clas in range(numPeople):\n",
        "            maskEndInd = nomaskEndInd = 0\n",
        "            for i in range(wantmaskInd, len(allmaskImages)):\n",
        "                if i+1 != len(allmaskImages):                \n",
        "                    if allmaskImages[i][1]!=allmaskImages[i+1][1]:\n",
        "                        maskEndInd = i+1\n",
        "                        break\n",
        "                else:\n",
        "                    maskEndInd = -1\n",
        "                    break\n",
        "            classmaskImages = []        \n",
        "            for i in range(wantmaskInd, maskEndInd if maskEndInd!=-1 else len(allmaskImages)):\n",
        "                classmaskImages.append(allmaskImages[i])\n",
        "            wantmaskInd = maskEndInd\n",
        "            \n",
        "            \n",
        "            for i in range(wantnomaskInd, len(allnomaskImages)):\n",
        "                if i+1 != len(allnomaskImages):                \n",
        "                    if allnomaskImages[i][1]!=allnomaskImages[i+1][1]:\n",
        "                        nomaskEndInd = i+1\n",
        "                        break\n",
        "                else:\n",
        "                    nomaskEndInd = -1\n",
        "                    break\n",
        "            classnomaskImages = []\n",
        "            for i in range(wantnomaskInd, nomaskEndInd if nomaskEndInd!=-1 else len(allnomaskImages)):\n",
        "                classnomaskImages.append(allnomaskImages[i])\n",
        "            wantnomaskInd = nomaskEndInd\n",
        "\n",
        "            # next, pair up \n",
        "            mask_train = classmaskImages[ :int(len(classmaskImages)*0.6)]\n",
        "            mask_val = classmaskImages[int(len(classmaskImages)*0.6):int(len(classmaskImages)*0.8)]\n",
        "            mask_test = classmaskImages[int(len(classmaskImages)*0.8):]\n",
        "            \n",
        "            for i in range(200):\n",
        "                int1 = np.random.randint(0, len(classnomaskImages)-1)\n",
        "                int2 = np.random.randint(0, len(mask_train)-1)\n",
        "                train_pair_list.append(([classnomaskImages[int1][0], mask_train[int2][0]], mask_train[int2][1]))\n",
        "\n",
        "            for i in range(80):\n",
        "                int1 = np.random.randint(0, len(classnomaskImages)-1)\n",
        "                int2 = np.random.randint(0, len(mask_val)-1)\n",
        "                val_pair_list.append(([classnomaskImages[int1][0], mask_val[int2][0]], mask_val[int2][1]))\n",
        "            for i in range(80):\n",
        "                int1 = np.random.randint(0, len(classnomaskImages)-1)\n",
        "                int2 = np.random.randint(0, len(mask_test)-1)\n",
        "                test_pair_list.append(([classnomaskImages[int1][0], mask_test[int2][0]], mask_val[int2][1]))\n",
        "\n",
        "        trainInd = range(len(train_pair_list))\n",
        "        valInd = range(len(val_pair_list))\n",
        "        testInd = range(len(test_pair_list))\n",
        "        trainSampler = SubsetRandomSampler(trainInd)\n",
        "        valSampler = SubsetRandomSampler(valInd)\n",
        "        testSampler = SubsetRandomSampler(testInd)\n",
        "        trainLoader = torch.utils.data.DataLoader(train_pair_list, batch_size=batchSize, sampler=trainSampler)\n",
        "        valLoader = torch.utils.data.DataLoader(val_pair_list, batch_size=batchSize, sampler=valSampler)\n",
        "        testLoader = torch.utils.data.DataLoader(test_pair_list, batch_size=batchSize, sampler=valSampler)\n",
        "        return trainLoader, valLoader, testLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84I9n-bbNbIV"
      },
      "source": [
        "# Current data_loader function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByrUGZK7qlk2"
      },
      "source": [
        "def getNewOneToOnePairLoader(maskRootAddr, nomaskRootAddr, batchSize=32, numPeople=20):\n",
        "    totalClassNum = 173\n",
        "    wantClass = totalClassNum-numPeople\n",
        "    \n",
        "    allmaskImages = datasets.ImageFolder(root=maskRootAddr, transform=transforms.ToTensor())\n",
        "    # get index of the first occurence of our desired class\n",
        "    wantmaskInd = wantnomaskInd = 0\n",
        "    for i in range(len(allmaskImages)):\n",
        "        if allmaskImages[1] == wantClass:\n",
        "            wantmaskInd = i\n",
        "            break\n",
        "            \n",
        "    allnomaskImages = datasets.ImageFolder(root=nomaskRootAddr, transform=transforms.ToTensor())\n",
        "    for i in range(len(allnomaskImages)):\n",
        "        if allmaskImages[1] == wantClass:\n",
        "            wantnomaskInd = i\n",
        "            break\n",
        "            \n",
        "    train_pair_list, val_pair_list, test_pair_list = [], [], []\n",
        "    \n",
        "    for clas in range(numPeople):\n",
        "        maskEndInd = nomaskEndInd = 0\n",
        "        for i in range(wantmaskInd, len(allmaskImages)):\n",
        "            if i+1 != len(allmaskImages):                \n",
        "                if allmaskImages[i][1]!=allmaskImages[i+1][1]:\n",
        "                    maskEndInd = i+1\n",
        "                    break\n",
        "            else:\n",
        "                maskEndInd = -1\n",
        "                break\n",
        "        classmaskImages = []        \n",
        "        for i in range(wantmaskInd, maskEndInd if maskEndInd!=-1 else len(allmaskImages)):\n",
        "            classmaskImages.append(allmaskImages[i])\n",
        "        wantmaskInd = maskEndInd\n",
        "        \n",
        "        \n",
        "        for i in range(wantnomaskInd, len(allnomaskImages)):\n",
        "            if i+1 != len(allnomaskImages):                \n",
        "                if allnomaskImages[i][1]!=allnomaskImages[i+1][1]:\n",
        "                    nomaskEndInd = i+1\n",
        "                    break\n",
        "            else:\n",
        "                nomaskEndInd = -1\n",
        "                break\n",
        "        classnomaskImages = []\n",
        "        for i in range(wantnomaskInd, nomaskEndInd if nomaskEndInd!=-1 else len(allnomaskImages)):\n",
        "            classnomaskImages.append(allnomaskImages[i])\n",
        "        wantnomaskInd = nomaskEndInd\n",
        "\n",
        "        # next, pair up\n",
        "        i = 0 \n",
        "        lenMaskImg = len(classnomaskImages)\n",
        "        label = classnomaskImages[0][1]\n",
        "        while i<100:\n",
        "            train_pair_list.append(([classnomaskImages[i%lenMaskImg][0], classmaskImages[i][0]], label))\n",
        "            i+=1\n",
        "        while i<130:\n",
        "            test_pair_list.append(([classnomaskImages[i%lenMaskImg][0], classmaskImages[i][0]], label))\n",
        "            i+=1\n",
        "        while i<160:\n",
        "            val_pair_list.append(([classnomaskImages[i%lenMaskImg][0], classmaskImages[i][0]], label))\n",
        "            i+=1\n",
        "            \n",
        "    trainInd = list(range(len(train_pair_list)))\n",
        "    np.random.shuffle(trainInd)\n",
        "    valInd = list(range(len(val_pair_list)))\n",
        "    np.random.shuffle(valInd)\n",
        "    testInd = list(range(len(test_pair_list)))\n",
        "    np.random.shuffle(testInd)\n",
        "    trainSampler = SubsetRandomSampler(trainInd)\n",
        "    valSampler = SubsetRandomSampler(valInd)\n",
        "    testSampler = SubsetRandomSampler(testInd)\n",
        "    trainLoader = torch.utils.data.DataLoader(train_pair_list, batch_size=batchSize, sampler=trainSampler)\n",
        "    valLoader = torch.utils.data.DataLoader(val_pair_list, batch_size=batchSize, sampler=valSampler)\n",
        "    testLoader = torch.utils.data.DataLoader(test_pair_list, batch_size=batchSize, sampler=valSampler)\n",
        "    return trainLoader, valLoader, testLoader\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-l70fQmvi9F"
      },
      "source": [
        "def getNewTrainANNLoader(maskAddr, nomaskAddr, batchsize=32, numPeople=20):\n",
        "\n",
        "    allnomaskImages = datasets.ImageFolder(root=nomaskAddr, transform=transforms.ToTensor())\n",
        "    wantInd = 0\n",
        "    for i in range(len(allnomaskImages)):\n",
        "        if allnomaskImages[i][1]==numPeople:\n",
        "            wantInd = i\n",
        "            break\n",
        "            \n",
        "    trainInd = list(range(wantInd))\n",
        "    np.random.shuffle(trainInd)\n",
        "    trainSampler = SubsetRandomSampler(trainInd)\n",
        "    trainLoader = torch.utils.data.DataLoader(allnomaskImages, batch_size=batchsize, sampler=trainSampler)\n",
        "\n",
        "\n",
        "    allmaskImages = datasets.ImageFolder(root=maskAddr, transform=transforms.ToTensor())\n",
        "    for i in range(len(allmaskImages)):\n",
        "        if allmaskImages[1]==numPeople:\n",
        "            wantInd = i\n",
        "            break\n",
        "            \n",
        "    allInd = list(range(wantInd))\n",
        "    np.random.shuffle(allInd)\n",
        "    \n",
        "    valInd = allInd[:int(0.5*len(allInd))]\n",
        "    testInd = allInd[int(0.5*len(allInd)):]\n",
        "    valSampler = SubsetRandomSampler(valInd)\n",
        "    testSampler = SubsetRandomSampler(testInd)\n",
        "    \n",
        "    valLoader = torch.utils.data.DataLoader(allmaskImages, batch_size=batchsize, sampler=valSampler)\n",
        "    testLoader = torch.utils.data.DataLoader(allmaskImages, batch_size=batchsize, sampler=testSampler)\n",
        "    return trainLoader, valLoader, testLoader\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1650kIXd9za"
      },
      "source": [
        "# Model status saving code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjiJvjIFkMMM"
      },
      "source": [
        "\"\"\"\n",
        "    Use \n",
        "    torch.save(model, PATH)\n",
        "    to save the parameters to the PATH\n",
        "\n",
        "    Use \n",
        "    model.load(PATH)\n",
        "    to load parameters from a file\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "    More info is here:\n",
        "    https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2jMsE1XeXis"
      },
      "source": [
        "def get_model_name(name, numPeopleForPair, numPeopleForANN, \n",
        "                   batch_size=32, learning_rate=0.01, epoch=15):\n",
        "    learningRateStr = str(learning_rate).split(\".\")\n",
        "    learningRateStr = learningRateStr[0]+learningRateStr[1]\n",
        "    path = \"model_{0}_npP{1}_npA{2}_bs{3}_lr{4}_epoch{5}\".format(name, numPeopleForPair, numPeopleForANN,\n",
        "                                                                     batch_size, learningRateStr, epoch)\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCUskAAZfYZa"
      },
      "source": [
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation error/loss.\n",
        "\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTRmtbmz5AAj"
      },
      "source": [
        "# Model Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsdX2sdv8bcT"
      },
      "source": [
        "Setup the model architecture for FDM_Model, which is used to generate the FDM that will be used to \"discard\" features on faces that will be covered if wearing a mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5ml1X74HzYS"
      },
      "source": [
        "# New Model\n",
        "# This is the model used to train both FDM and ANN together in one model\n",
        "# Input: a pair of features derived from pretrained ResNet 50\n",
        "# Output: 1. fdm: array with the same dimension as the features\n",
        "#         2. a pair of filtered features\n",
        "#         3. classification result\n",
        "\n",
        "class FDMClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FDMClassifier, self).__init__()\n",
        "    # 1 * 1 convolution to maintain the size\n",
        "    self.conv1 = nn.Conv2d(2048, 2048, 1) #in_channels, out_chanels, kernel_size\n",
        "    # only need a single fc layer\n",
        "    self.fc1 = nn.Linear(2048, 20)\n",
        "  \n",
        "  def forward(self, mask, nomask):\n",
        "    # generate fdm\n",
        "    fdm = F.relu(self.conv1(mask - nomask))\n",
        "\n",
        "    # apply fdm to do filtering\n",
        "    mask_filtered = mask * fdm\n",
        "    nomask_filtered = nomask * fdm\n",
        "\n",
        "    # classification, using masked faces\n",
        "    x = mask_filtered.view(-1, 2048) # flatten the input\n",
        "    x = self.fc1(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return (mask_filtered, nomask_filtered, x) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvD9ziGiR3Vj"
      },
      "source": [
        "# This model is used to do classification of faces.\n",
        "# Input: features of faces derived from pretrained ResNet 50, after multiplying\n",
        "# with FDM to discard mask-covered features\n",
        "# Output: classification result\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    # only need a single fc layer\n",
        "    self.fc1 = nn.Linear(2048, 20)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Classification\n",
        "    x = x.view(-1, 2048) # flatten the input\n",
        "    x = self.fc1(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dqJCRbHmwN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "a54de338ce7846a984c495bbbdccb69d",
            "797da68db93542d0ba0348bb9ca8761d",
            "54c80fcdc377426ab0e25b2578208ac4",
            "7f94438b97a24625b4cee26b23f454f6",
            "1f59498010104ca8a10eb0c2466fa3aa",
            "f960aced4e0f42baae608c8735cf7a33",
            "ade0b1354ac242378f15c7f79b6a3e4b",
            "158513e40e2140a5a85abce9956bfa31"
          ]
        },
        "outputId": "7163e2fb-aaa1-4693-db54-112823c95e33"
      },
      "source": [
        " # This is resnet50 pretrained model \n",
        " # Extracts features from last hidden layer of resnet50\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "modules = list(resnet50.children())[:-1]\n",
        "resnet50 = nn.Sequential(*modules)\n",
        "# tell the model not to learn or modify the weights / parameters of the model\n",
        "for p in resnet50.parameters():\n",
        "    p.requires_grad = False"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a54de338ce7846a984c495bbbdccb69d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29C7o8fk5VbR"
      },
      "source": [
        "# get_accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uTRqmliUtTQ"
      },
      "source": [
        "# New get_accuracy function\n",
        "def get_accuracy(pretrained_cnn, fdm_classifier_model, data_loader, batch_size):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # Get the inputs\n",
        "    inputs, labels = data\n",
        "    mask = inputs[0]\n",
        "    nomask = inputs[1]\n",
        "    \n",
        "    if mask.shape[0] != batch_size:\n",
        "      continue\n",
        "    \n",
        "\n",
        "    mask_conv = pretrained_cnn(mask)\n",
        "    nomask_conv = pretrained_cnn(nomask)\n",
        "\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        mask_conv = mask_conv.cuda()\n",
        "        nomask_conv = nomask_conv.cuda()\n",
        "        labels = labels.cuda()\n",
        "    #############################################\n",
        "\n",
        "    mask_filtered, nomask_filtered, output = fdm_classifier_model(mask_conv, nomask_conv)\n",
        "\n",
        "    #select index with maximum prediction score\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    total += mask.shape[0]\n",
        "\n",
        "  return correct / total\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLXZzL2ONblO"
      },
      "source": [
        "# Baseline get_accuracy function\n",
        "def get_accuracy_baseline(pretrained_cnn, classifier_model, data_loader, batch_size):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # Get the inputs\n",
        "    inputs, labels = data\n",
        "    mask = inputs[0]\n",
        "    \n",
        "    if mask.shape[0] != batch_size:\n",
        "      continue\n",
        "    \n",
        "\n",
        "    mask_conv = pretrained_cnn(mask)\n",
        "\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        mask_conv = mask_conv.cuda()\n",
        "        labels = labels.cuda()\n",
        "    #############################################\n",
        "\n",
        "    output = classifier_model(mask_conv)\n",
        "\n",
        "    #select index with maximum prediction score\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    total += mask.shape[0]\n",
        "\n",
        "  return correct / total\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS_BDGfswL8x"
      },
      "source": [
        "# get_accuracy function for the second stage of training: fix FDM and train ANN\n",
        "def get_accuracy_classifier(pretrained_cnn, fdm, classifier_model, data_loader, batch_size):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # Get the inputs\n",
        "    inputs, labels = data\n",
        "    \n",
        "    if inputs.shape[0] != batch_size:\n",
        "      continue\n",
        "    \n",
        "    conv_features = pretrained_cnn(inputs)\n",
        "    filtered_features = conv_features * fdm\n",
        "\n",
        "    #############################################\n",
        "    #To Enable GPU Usage\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        filtered_features = filtered_features.cuda()\n",
        "        labels = labels.cuda()\n",
        "    #############################################\n",
        "\n",
        "    output = classifier_model(filtered_features)\n",
        "\n",
        "    #select index with maximum prediction score\n",
        "    pred = output.max(1, keepdim=True)[1]\n",
        "    correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    total += inputs.shape[0]\n",
        "\n",
        "  return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ny9JJrO1Jb1"
      },
      "source": [
        "# train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvomB7wqWPxx"
      },
      "source": [
        "# Train function 1: train FDM + ANN\n",
        "def train(pretrained_cnn, fdm_classifier_model, train_pair_loader, valid_pair_loader, batch_size, num_epochs = 5, learning_rate=1e-3):\n",
        "\n",
        "  torch.manual_seed(1) # set the random seed\n",
        "\n",
        "  criterionFDM = nn.MSELoss() # mean square error loss to train FDM\n",
        "  criterionClassifier = nn.CrossEntropyLoss() # CE loss for classification of multiple classes\n",
        "  optimizer = torch.optim.Adam(fdm_classifier_model.parameters(), lr = learning_rate) # use Adam optimizer\n",
        "\n",
        "  epochs, every_iteration, fdm_losses, classifier_losses, losses, train_acc, valid_acc = [], [], [], [], [], [], []\n",
        "  iter = 0\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch\", epoch)\n",
        "    for i, data in enumerate(train_pair_loader):\n",
        "      iter += 1\n",
        "      print(\"batch\", i)\n",
        "      # Get the inputs\n",
        "      inputs, labels = data\n",
        "      inputs_mask = inputs[0]\n",
        "      inputs_nomask = inputs[1]\n",
        "\n",
        "      # Discard the last batch to make size of fdm consistent\n",
        "      if inputs_mask.shape[0] != batch_size:\n",
        "        continue\n",
        "      \n",
        "\n",
        "      mask_conv = pretrained_cnn(inputs_mask)\n",
        "      nomask_conv = pretrained_cnn(inputs_nomask)\n",
        "\n",
        "      #############################################\n",
        "      #To Enable GPU Usage\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "          mask_conv = mask_conv.cuda()\n",
        "          nomask_conv = nomask_conv.cuda()\n",
        "          labels = labels.cuda()\n",
        "      #############################################\n",
        "\n",
        "      mask_filtered, nomask_filtered, out = fdm_classifier_model(mask_conv, nomask_conv)\n",
        "\n",
        "      fdm_loss = criterionFDM(mask_filtered, nomask_filtered) # The first loss is contrastive loss\n",
        "\n",
        "      classifier_loss = criterionClassifier(out, labels)\n",
        "      print(\"contrastive loss is\", fdm_loss)\n",
        "      print(\"classification loss is\", classifier_loss)\n",
        "\n",
        "      every_iteration.append(iter)\n",
        "      fdm_losses.append(float(fdm_loss))\n",
        "      classifier_losses.append(float(classifier_loss))\n",
        "\n",
        "      total_loss = fdm_loss * 1 + classifier_loss\n",
        "      print(\"total loss is\", total_loss)\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    # get accuracy for every epoch\n",
        "    train_accuracy = get_accuracy(pretrained_cnn, fdm_classifier_model, train_pair_loader, batch_size)\n",
        "    valid_accuracy = get_accuracy(pretrained_cnn, fdm_classifier_model, valid_pair_loader, batch_size)\n",
        "    print(\"train accuracy is\", train_accuracy)\n",
        "    print(\"validation accuracy is\", valid_accuracy)\n",
        "    train_acc.append(train_accuracy)\n",
        "    valid_acc.append(valid_accuracy)\n",
        "    losses.append(float(total_loss))\n",
        "    epochs.append(epoch)\n",
        "    ## Add code here\n",
        "\n",
        "  # plotting contrastive loss curve\n",
        "  plt.title(\"Contrastive Loss Curve\")\n",
        "  plt.plot(every_iteration, fdm_losses, label=\"Contrastive Loss\")\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  # plotting classification loss curve\n",
        "  plt.title(\"Classification Loss Curve\")\n",
        "  plt.plot(every_iteration, classifier_losses, label=\"Classification Loss\")\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  # plotting overall loss curve\n",
        "  plt.title(\"Loss Curve\")\n",
        "  plt.plot(epochs, losses, label=\"Train\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  # plotting accuracy curve\n",
        "  plt.title(\"Accuracy Curve\")\n",
        "  plt.plot(epochs, train_acc, label=\"Train\")\n",
        "  plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjqNU1TWMeAm"
      },
      "source": [
        "# Train function 1: train FDM + ANN\n",
        "def trainBaseline(pretrained_cnn, classifier_model, train_pair_loader, valid_pair_loader, batch_size, num_epochs = 5, learning_rate=1e-3):\n",
        "\n",
        "  torch.manual_seed(1) # set the random seed\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss() # CE loss for classification of multiple classes\n",
        "  optimizer = torch.optim.Adam(classifier_model.parameters(), lr = learning_rate) # use Adam optimizer\n",
        "\n",
        "  epochs, every_iteration, iteration_losses, train_acc, valid_acc = [], [], [], [], []\n",
        "  iter = 0\n",
        " \n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch\", epoch)\n",
        "    for i, data in enumerate(train_pair_loader):\n",
        "      iter += 1\n",
        "      print(\"batch\", i)\n",
        "      # Get the inputs\n",
        "      inputs, labels = data\n",
        "      inputs_mask = inputs[0]\n",
        "      inputs_nomask = inputs[1]\n",
        "\n",
        "      # Discard the last batch to make size of fdm consistent\n",
        "      if inputs_mask.shape[0] != batch_size:\n",
        "        continue\n",
        "      \n",
        "\n",
        "      mask_conv = pretrained_cnn(inputs_mask)\n",
        "\n",
        "      #############################################\n",
        "      #To Enable GPU Usage\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "          mask_conv = mask_conv.cuda()\n",
        "          labels = labels.cuda()\n",
        "      #############################################\n",
        "\n",
        "      out = classifier_model(mask_conv)\n",
        "\n",
        "      loss = criterion(out, labels)\n",
        "\n",
        "      print(\"classification loss is\", loss)\n",
        "\n",
        "      every_iteration.append(iter)\n",
        "      iteration_losses.append(float(loss))\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    # get accuracy for every epoch\n",
        "    train_accuracy = get_accuracy_baseline(pretrained_cnn, classifier_model, train_pair_loader, batch_size)\n",
        "    valid_accuracy = get_accuracy_baseline(pretrained_cnn, classifier_model, valid_pair_loader, batch_size)\n",
        "    print(\"train accuracy is\", train_accuracy)\n",
        "    print(\"validation accuracy is\", valid_accuracy)\n",
        "    train_acc.append(train_accuracy)\n",
        "    valid_acc.append(valid_accuracy)\n",
        "    epochs.append(epoch)\n",
        "    ## Add code here\n",
        "\n",
        "\n",
        "  # plotting every iteration loss curve\n",
        "  plt.title(\"Loss Curve\")\n",
        "  plt.plot(every_iteration, iteration_losses, label=\"Loss\")\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  # plotting accuracy curve\n",
        "  plt.title(\"Accuracy Curve\")\n",
        "  plt.plot(epochs, train_acc, label=\"Train\")\n",
        "  plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZWkE8fztvGd"
      },
      "source": [
        "# Train function 2: fix FDM, train ANN only\n",
        "\n",
        "def trainANN(pretrained_cnn, classifier_model, fdm, train_loader, valid_loader, batch_size, num_epochs = 5, learning_rate=1e-3):\n",
        "\n",
        "  torch.manual_seed(1) # set the random seed\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss() # CE loss for classification of multiple classes\n",
        "  optimizer = torch.optim.Adam(classifier_model.parameters(), lr = learning_rate) # use Adam optimizer\n",
        "\n",
        "  every_iteration, epochs, losses, train_acc, valid_acc = [], [], [], [], []\n",
        "\n",
        "  iter = 0\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch\", epoch)\n",
        "    for i, data in enumerate(train_loader):\n",
        "      iter += 1\n",
        "      print(\"batch\", i)\n",
        "      # Get the inputs\n",
        "      inputs, labels = data\n",
        "      \n",
        "\n",
        "      # Discard the last batch to make size of fdm consistent\n",
        "      if inputs.shape[0] != batch_size:\n",
        "        continue\n",
        "\n",
        "      # Use unmasked faces to train\n",
        "      nomask_conv = pretrained_cnn(inputs)\n",
        "\n",
        "      # Use fixed FDM to discard some features\n",
        "      nomask_filtered = nomask_conv * fdm\n",
        "\n",
        "      #############################################\n",
        "      #To Enable GPU Usage\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "          nomask_filtered = nomask_filtered.cuda()\n",
        "          labels = labels.cuda()\n",
        "      #############################################\n",
        "\n",
        "      out = classifier_model(nomask_filtered)\n",
        "      \n",
        "      loss = criterion(out, labels) # Classification loss\n",
        "\n",
        "      print(\"loss is\", loss)\n",
        "      every_iteration.append(iter)\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    # record for every epoch   \n",
        "    epochs.append(epoch)\n",
        "    train_accuracy = get_accuracy_classifier(pretrained_cnn, fdm, classifier_model, train_loader, batch_size)\n",
        "    valid_accuracy = get_accuracy_classifier(pretrained_cnn, fdm, classifier_model, valid_loader, batch_size)\n",
        "    print(\"train accuracy is\", train_accuracy)\n",
        "    print(\"validation accuracy is\", valid_accuracy)\n",
        "    train_acc.append(train_accuracy)\n",
        "    valid_acc.append(valid_accuracy)\n",
        "\n",
        "  # plotting loss curve\n",
        "  plt.title(\"Loss Curve\")\n",
        "  plt.plot(every_iteration, losses, label=\"Loss\")\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  # plotting accuracy curve\n",
        "  plt.title(\"Accuracy Curve\")\n",
        "  plt.plot(epochs, train_acc, label=\"Train\")\n",
        "  plt.plot(epochs, valid_acc, label=\"Validation\")\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMq9dkp0bGVz"
      },
      "source": [
        "# 1st stage of training: train FDM + ANN, but the purpose is to train FDM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKVPkPZmarGf"
      },
      "source": [
        "maskRootAddr = '/content/drive/My Drive/Colab Notebooks/new-one2one-pair-dataset/mask/'\n",
        "nomaskRootAddr = '/content/drive/My Drive/Colab Notebooks/new-one2one-pair-dataset/nomask/'\n",
        "\n",
        "new_train_pair_loader, new_valid_pair_loader, new_test_pair_loader = getNewOneToOnePairLoader(maskRootAddr, nomaskRootAddr, 128, 20)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsu0z5UCdtYO"
      },
      "source": [
        "for i, data in enumerate(new_train_pair_loader):\n",
        "  print(i)\n",
        "  # Get the inputs\n",
        "  inputs, labels = data\n",
        "  mask = inputs[0]\n",
        "  \n",
        "  nomask = inputs[1]\n",
        "  print(labels)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-btzizt6Ure",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "212c4380-7e0d-4eeb-9656-574d2f58e0cb"
      },
      "source": [
        "# One click to train\n",
        "\n",
        "fdm_classifier_model = FDMClassifier()\n",
        "\n",
        "#Use GPU\n",
        "use_cuda = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  fdm_classifier_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "  \n",
        "#proper model\n",
        "train(resnet50, fdm_classifier_model, new_train_pair_loader, new_valid_pair_loader, 128, 8, 0.0008)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Epoch 0\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.9995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(3.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.8857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.8922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0070, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.7742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.6669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.5570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.4226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.4334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.3118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.3243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.0526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.0678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(2.0564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(2.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0182, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.9652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.9833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.8369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.8592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0258, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.6338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.6596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.5831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.6158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.6477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.3927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.4264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 0.8484375\n",
            "validation accuracy is 0.763671875\n",
            "Epoch 1\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(1.0428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.0827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.9559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.9993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.9915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(1.0343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.9402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.7643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.8176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0546, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.6340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.6886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.6972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.7531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0610, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.5798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.6409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.6538, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.7163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0686, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.5183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.5870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.5537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0717, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.5707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0715, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.4217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.5596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.4460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 0.9583333333333334\n",
            "validation accuracy is 0.84765625\n",
            "Epoch 2\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0725, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.4218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.4943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.3159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.2318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.2871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0799, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0905, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0927, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0910, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 0.9953125\n",
            "validation accuracy is 0.892578125\n",
            "Epoch 3\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0869, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0899, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0941, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0887, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.1057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1944, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0895, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0939, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0933, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0943, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0934, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0932, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0913, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 0.9989583333333333\n",
            "validation accuracy is 0.8984375\n",
            "Epoch 4\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0930, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0877, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0902, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0899, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0869, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0880, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0893, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0835, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0919, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 1.0\n",
            "validation accuracy is 0.916015625\n",
            "Epoch 5\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0806, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0733, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 1.0\n",
            "validation accuracy is 0.927734375\n",
            "Epoch 6\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0732, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0716, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0692, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0705, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 1.0\n",
            "validation accuracy is 0.91796875\n",
            "Epoch 7\n",
            "batch 0\n",
            "contrastive loss is tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 1\n",
            "contrastive loss is tensor(0.0715, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 2\n",
            "contrastive loss is tensor(0.0673, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 3\n",
            "contrastive loss is tensor(0.0704, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 4\n",
            "contrastive loss is tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 5\n",
            "contrastive loss is tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 6\n",
            "contrastive loss is tensor(0.0650, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 7\n",
            "contrastive loss is tensor(0.0671, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 8\n",
            "contrastive loss is tensor(0.0641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 9\n",
            "contrastive loss is tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 10\n",
            "contrastive loss is tensor(0.0654, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 11\n",
            "contrastive loss is tensor(0.0651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 12\n",
            "contrastive loss is tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 13\n",
            "contrastive loss is tensor(0.0603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 14\n",
            "contrastive loss is tensor(0.0639, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "classification loss is tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "total loss is tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "batch 15\n",
            "train accuracy is 1.0\n",
            "validation accuracy is 0.923828125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0z3TjNvx52G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f002f37-37bf-4b3f-93fb-70d2023af385"
      },
      "source": [
        "test_accuracy = get_accuracy(resnet50, fdm_classifier_model, new_test_pair_loader, 128)\n",
        "print(\"Test accuracy is\", test_accuracy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.923828125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpy9SeCGObzI",
        "outputId": "0a66e525-1f11-4744-e466-06271d4e7ece"
      },
      "source": [
        "# Train baseline CNN model\n",
        "classifier_model = Classifier()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  classifier_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "  \n",
        "#proper model\n",
        "trainBaseline(resnet50, classifier_model, new_train_pair_loader, new_valid_pair_loader, 128, 20, 0.0008)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Epoch 0\n",
            "batch 0\n",
            "classification loss is tensor(3.0104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(3.0856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(3.1186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(2.9957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(2.9403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(2.9852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(2.9839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(2.9227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(2.9552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(2.8897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(2.9316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(2.7979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(2.8588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(2.8652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(2.7839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.2328125\n",
            "validation accuracy is 0.1953125\n",
            "Epoch 1\n",
            "batch 0\n",
            "classification loss is tensor(2.6955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(2.5980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(2.7016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(2.6453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(2.6385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(2.6335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(2.6949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(2.6009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(2.5727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(2.5868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(2.5515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(2.4628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(2.5541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(2.5384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(2.5820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.2989583333333333\n",
            "validation accuracy is 0.25\n",
            "Epoch 2\n",
            "batch 0\n",
            "classification loss is tensor(2.4908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(2.3991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(2.4203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(2.4899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(2.3374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(2.2446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(2.4186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(2.4913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(2.3469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(2.3351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(2.4341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(2.3325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(2.3207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(2.3924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(2.4085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.38125\n",
            "validation accuracy is 0.29296875\n",
            "Epoch 3\n",
            "batch 0\n",
            "classification loss is tensor(2.2664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(2.1585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(2.2519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(2.2674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(2.1994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(2.2450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(2.3584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(2.0840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(2.1240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(2.1623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(2.1696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(2.1669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(2.1600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.44375\n",
            "validation accuracy is 0.35546875\n",
            "Epoch 4\n",
            "batch 0\n",
            "classification loss is tensor(2.1497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(2.1795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(2.0937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(2.1297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(2.0600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(2.0307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.9932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.9528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.9659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(2.0266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(2.1459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.9615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(2.0539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.9655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.45989583333333334\n",
            "validation accuracy is 0.35546875\n",
            "Epoch 5\n",
            "batch 0\n",
            "classification loss is tensor(1.9671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.9579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(2.0959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.8513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.9228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.9382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.9308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.9566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.9725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(2.0737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.9612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.9640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.8784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(2.0050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5307291666666667\n",
            "validation accuracy is 0.439453125\n",
            "Epoch 6\n",
            "batch 0\n",
            "classification loss is tensor(1.7950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.9377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.8591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.7904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.9262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.9523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.8918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.8429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.9064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.8620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.8495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.7594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.9998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.8472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.7972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5\n",
            "validation accuracy is 0.3984375\n",
            "Epoch 7\n",
            "batch 0\n",
            "classification loss is tensor(1.6974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.8506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.8115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.7567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.8157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.6985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.7291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.8081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.7012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.9220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.9954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.8914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.8021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.8374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.7040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5244791666666667\n",
            "validation accuracy is 0.416015625\n",
            "Epoch 8\n",
            "batch 0\n",
            "classification loss is tensor(1.8108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.7563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.6685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.8363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.7492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.6979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.6701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.6161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.8099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.6792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.8535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.7992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.7579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.5743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.6759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5515625\n",
            "validation accuracy is 0.421875\n",
            "Epoch 9\n",
            "batch 0\n",
            "classification loss is tensor(1.7006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.5706, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.5716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.5691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.8000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.5947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.7489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.7623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.6583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.5998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.6362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.6817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.7157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.6366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.6779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5739583333333333\n",
            "validation accuracy is 0.46484375\n",
            "Epoch 10\n",
            "batch 0\n",
            "classification loss is tensor(1.7151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.5414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.5704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.6739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.5730, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.5574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.5469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.4891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.6933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.5254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.6208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.5527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.6244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.7533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.7058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5859375\n",
            "validation accuracy is 0.427734375\n",
            "Epoch 11\n",
            "batch 0\n",
            "classification loss is tensor(1.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.5268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.5388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.5517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.5095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.5796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.5267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.4274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.6306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.6641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.5085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.6334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.7083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.6186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.5635416666666667\n",
            "validation accuracy is 0.4296875\n",
            "Epoch 12\n",
            "batch 0\n",
            "classification loss is tensor(1.3875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.5795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.4249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.6129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.4712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.5665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.6326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.6207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.4297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.4876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.5269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.5658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.5145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.5097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.5454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6135416666666667\n",
            "validation accuracy is 0.451171875\n",
            "Epoch 13\n",
            "batch 0\n",
            "classification loss is tensor(1.5642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.5432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.3791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.5026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.4725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.4635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.3331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.3829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.4600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.5106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.4397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.5199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.3943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.4744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6270833333333333\n",
            "validation accuracy is 0.486328125\n",
            "Epoch 14\n",
            "batch 0\n",
            "classification loss is tensor(1.4501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.3667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.4555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.3972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.3996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.4318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.5841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.4462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.4818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.4003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.4906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.4506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.4429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.4227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.3437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6447916666666667\n",
            "validation accuracy is 0.46875\n",
            "Epoch 15\n",
            "batch 0\n",
            "classification loss is tensor(1.2921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.3966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.4090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.3849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.3737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.3610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.3937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.3989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.3851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.3602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.4612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.4722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.2424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.3712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.2727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6427083333333333\n",
            "validation accuracy is 0.482421875\n",
            "Epoch 16\n",
            "batch 0\n",
            "classification loss is tensor(1.2535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.3814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.4515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.3747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.3677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.3356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.2353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.4355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.3346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.3651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.3665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.2771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.4524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.2667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.2842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6760416666666667\n",
            "validation accuracy is 0.490234375\n",
            "Epoch 17\n",
            "batch 0\n",
            "classification loss is tensor(1.2812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.3159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.2997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.4456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.2331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.3664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.3514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.3816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.3861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.4215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.3767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.2994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.2244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.1570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6791666666666667\n",
            "validation accuracy is 0.470703125\n",
            "Epoch 18\n",
            "batch 0\n",
            "classification loss is tensor(1.4347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.3140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.3828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.3236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.3401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.2594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.1454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.2372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.3197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.1580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.3900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.2533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.2573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.3275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.4147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.6802083333333333\n",
            "validation accuracy is 0.484375\n",
            "Epoch 19\n",
            "batch 0\n",
            "classification loss is tensor(1.2375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "classification loss is tensor(1.3124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "classification loss is tensor(1.1918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "classification loss is tensor(1.3789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "classification loss is tensor(1.2520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "classification loss is tensor(1.3281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "classification loss is tensor(1.5313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "classification loss is tensor(1.2159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "classification loss is tensor(1.2720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "classification loss is tensor(1.3660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "classification loss is tensor(1.3333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "classification loss is tensor(1.1544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "classification loss is tensor(1.2401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "classification loss is tensor(1.2614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "classification loss is tensor(1.2201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "train accuracy is 0.68125\n",
            "validation accuracy is 0.490234375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "pL_DHKxZcdAN",
        "outputId": "7700018f-8d69-4a5d-8976-ecb7388b846c"
      },
      "source": [
        "test_accuracy = get_accuracy_baseline(resnet50, classifier_model, new_test_pair_loader, 128)\n",
        "print(\"Baseline model test accuracy is\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-de6350c89551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test_pair_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline model test accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_accuracy_baseline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARGQSsusf9qg"
      },
      "source": [
        "# 2nd stage of training: using fixed FDM to train ANN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aPOKCq9jXhj"
      },
      "source": [
        "train_ann_loader, valid_ann_loader, test_an_loader = getNewTrainANNLoader(maskRootAddr, nomaskRootAddr, 128, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMAESGhmlhb"
      },
      "source": [
        "# Check size of inputs\n",
        "for imgs, labels in train_ann_loader:\n",
        "  print(\"1\")\n",
        "  \n",
        "  print(imgs.shape)\n",
        "  # x = x.permute(1, 2, 0)      # move the channel dimension to the end to plot\n",
        "  # plt.imshow(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2RE-Uo0YkV9d",
        "outputId": "6f681f22-ed67-4638-bdd8-487e0def1de6"
      },
      "source": [
        "\n",
        "classifier_model = Classifier()\n",
        "\n",
        "#Use GPU\n",
        "use_cuda = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  classifier_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "  \n",
        "#proper model\n",
        "trainANN(resnet50, classifier_model, fdm, train_ann_loader, valid_ann_loader, 128, 7, 0.002)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Epoch 0\n",
            "batch 0\n",
            "loss is tensor(2.9976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "loss is tensor(2.9880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "loss is tensor(2.9848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "loss is tensor(2.9668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "loss is tensor(2.9415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "loss is tensor(2.9575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "loss is tensor(2.9766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "loss is tensor(2.9481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "loss is tensor(2.9596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "loss is tensor(2.9389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "loss is tensor(2.9767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "loss is tensor(2.9742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "loss is tensor(2.8932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "loss is tensor(2.9361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "loss is tensor(2.9634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "loss is tensor(3.0085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 16\n",
            "loss is tensor(2.9363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 17\n",
            "loss is tensor(2.8972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 18\n",
            "loss is tensor(2.9031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 19\n",
            "loss is tensor(2.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 20\n",
            "loss is tensor(2.9299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 21\n",
            "loss is tensor(2.9253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 22\n",
            "loss is tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 23\n",
            "loss is tensor(2.9196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 24\n",
            "loss is tensor(2.8701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 25\n",
            "loss is tensor(2.8890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 26\n",
            "loss is tensor(2.9255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 27\n",
            "loss is tensor(2.8595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 28\n",
            "train accuracy is 0.125\n",
            "validation accuracy is 0.03794642857142857\n",
            "Epoch 1\n",
            "batch 0\n",
            "loss is tensor(2.9079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 1\n",
            "loss is tensor(2.8623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 2\n",
            "loss is tensor(2.8605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 3\n",
            "loss is tensor(2.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 4\n",
            "loss is tensor(2.8575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 5\n",
            "loss is tensor(2.8773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 6\n",
            "loss is tensor(2.8830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 7\n",
            "loss is tensor(2.8621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 8\n",
            "loss is tensor(2.8793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 9\n",
            "loss is tensor(2.8675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 10\n",
            "loss is tensor(2.8420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 11\n",
            "loss is tensor(2.8212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 12\n",
            "loss is tensor(2.8974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 13\n",
            "loss is tensor(2.8579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 14\n",
            "loss is tensor(2.9038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 15\n",
            "loss is tensor(2.8652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 16\n",
            "loss is tensor(2.8258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 17\n",
            "loss is tensor(2.8627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 18\n",
            "loss is tensor(2.8410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 19\n",
            "loss is tensor(2.8523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 20\n",
            "loss is tensor(2.8695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 21\n",
            "loss is tensor(2.8344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 22\n",
            "loss is tensor(2.8326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 23\n",
            "loss is tensor(2.8254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 24\n",
            "loss is tensor(2.8230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 25\n",
            "loss is tensor(2.8276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 26\n",
            "loss is tensor(2.8792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 27\n",
            "loss is tensor(2.8520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "batch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-df47c2af9015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#proper model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ann_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ann_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-88-baf7035e870b>\u001b[0m in \u001b[0;36mtrainANN\u001b[0;34m(pretrained_cnn, classifier_model, fdm, train_loader, valid_loader, batch_size, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# record for every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mvalid_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f7ba34abfc40>\u001b[0m in \u001b[0;36mget_accuracy_classifier\u001b[0;34m(pretrained_cnn, fdm, classifier_model, data_loader, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mconv_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mfiltered_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m     )\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x70fT_nGlMtR"
      },
      "source": [
        "def trainANN(pretrained_cnn, classifier_model, fdm, train_loader, valid_loader, batch_size, num_epochs = 5, learning_rate=1e-3):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DW2cqHlRExt"
      },
      "source": [
        "# Baseline Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zHrZXBthvKE"
      },
      "source": [
        "SVM Link: https://colab.research.google.com/drive/1ootPn-Rpa7Xc96RRlHmYdbC9GsC1LIzg?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tndyWkEBbiwV"
      },
      "source": [
        "maskRootAddr_2 = '/content/drive/My Drive/Colab Notebooks/pair-dataset/mask/'\n",
        "nomaskRootAddr_2 = '/content/drive/My Drive/Colab Notebooks/pair-dataset/nomask/'\n",
        "\n",
        "class BaselineCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNClassifier, self).__init__() #Input 3*244*244\n",
        "        self.name=\"BaselineCNN\"\n",
        "        self.conv1 = nn.Conv2d(3, 5, 5) #in_channels, out_chanels, kernel_size (5*220*220)\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride (size after pooling 5*110*110)\n",
        "        self.conv2 = nn.Conv2d(5, 10, 5) #in_channels, out_chanels, kernel_size (size 10*106*106, after pooling 10*53*53)\n",
        "        self.fc1 = nn.Linear(53*53*10, 120) \n",
        "        self.fc2 = nn.Linear(120, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 53*53*10)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def get_accuracy_baseline(model, data_loader):\n",
        "    #data can be train_loader, val_loader, or small_loader\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, labels in data_loader:\n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total\n",
        "  \n",
        "def trainBaseline(model, batch_size = 32, num_epochs=1, learning_rate = 0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            #############################################\n",
        "              \n",
        "            out = model(imgs)             # forward pass\n",
        "\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "        # save the current training information\n",
        "        iters.append(n)\n",
        "        losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "\n",
        "        train_acc.append(get_accuracy_baseline(model, baseline_train_loader)) # compute training accuracy \n",
        "        val_acc.append(get_accuracy_baseline(model, baseline_val_loader))  # compute validation accuracy\n",
        "        n += 1\n",
        "        print(\"Epoch: \", epoch, \", training accuracy: \", train_acc[-1], \"validation accuracy: \", val_acc[-1]) \n",
        "          \n",
        "        path = \"baseline_model_{0}_lr{1}_epoch{2}\".format(model.name, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), path)     \n",
        "\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtXkeRqRbvkb"
      },
      "source": [
        "baseline_train_loader, baseline_val_loader, baseline_test_loader = getNewTrainANNLoader(maskAddr, nomaskAddr, batchsize=32, numPeople=20):\n",
        "baselineModel = BaselineCNN()\n",
        "trainBaseline(baselineModel, batch_size = 32, num_epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}